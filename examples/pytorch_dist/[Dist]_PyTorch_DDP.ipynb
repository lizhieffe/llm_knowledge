{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN0aa4u8VPUzV6LsCcV4CMt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lizhieffe/llm_knowledge/blob/main/examples/pytorch_dist/%5BDist%5D_PyTorch_DDP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Reference: https://zhuanlan.zhihu.com/p/178402798\n",
        "- Good read about the mechanism:\n",
        "  - https://zhuanlan.zhihu.com/p/187610959\n",
        "  - https://zhuanlan.zhihu.com/p/250471767\n",
        "  - https://zhuanlan.zhihu.com/p/485208899"
      ],
      "metadata": {
        "id": "1uxUUCXZ9_T3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Single GPU"
      ],
      "metadata": {
        "id": "U6XXpSa1FRZZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "DEVICE = 'cpu'\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "# Init\n",
        "input = torch.randn(20, 10).to(DEVICE) # (20, 10)\n",
        "labels = torch.randn(20, 10).to(DEVICE)\n",
        "\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "\n",
        "model = torch.nn.Linear(10, 10).to(DEVICE)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1)\n",
        "\n",
        "for it in range(1):\n",
        "  # forward\n",
        "  optimizer.zero_grad()\n",
        "  outputs = model(input)\n",
        "\n",
        "  # Assert the grad is None before backprop\n",
        "  for name, p in model.named_parameters():\n",
        "    assert not p.grad\n",
        "    # print(f\"{p=}\")\n",
        "\n",
        "  # backward\n",
        "  loss_fn(outputs, labels).backward()\n",
        "\n",
        "  # Assert the grad is not None after backprop\n",
        "  for name, p in model.named_parameters():\n",
        "    if p.requires_grad:\n",
        "      assert p.grad is not None\n",
        "      assert p.shape == p.grad.shape\n",
        "      # print(f\"{p.grad=}\")\n",
        "      # print(f\"{p=}\")\n",
        "\n",
        "  optimizer.step()\n",
        "\n",
        "  # check model params\n",
        "  print(f\"In epoch {it}\")\n",
        "  for name, param in model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "      print(f\"{name=}, {param.data=}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g90S9hU6BQ2D",
        "outputId": "7fe8c564-6fcd-461a-f84f-b22dbe8f4629"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In epoch 0\n",
            "name='weight', param.data=tensor([[ 0.0944, -0.1266, -0.1251,  0.1248, -0.0659, -0.0834,  0.1643, -0.1748,\n",
            "          0.1602,  0.2234],\n",
            "        [-0.1549, -0.2573,  0.0233, -0.1648,  0.1694, -0.1869, -0.2008, -0.0400,\n",
            "         -0.0904, -0.2047],\n",
            "        [ 0.1007,  0.1481,  0.0845,  0.1624,  0.0025,  0.2104, -0.2733,  0.2917,\n",
            "          0.1926, -0.1286],\n",
            "        [-0.0789, -0.1440,  0.2480,  0.0249,  0.0506,  0.2015, -0.1588,  0.2132,\n",
            "         -0.2207, -0.1388],\n",
            "        [-0.0530, -0.2940, -0.2188, -0.2619, -0.1186, -0.1148, -0.0541,  0.0963,\n",
            "         -0.0057, -0.1375],\n",
            "        [-0.2125,  0.2258, -0.2172, -0.1571, -0.1958,  0.2219,  0.2494,  0.0186,\n",
            "         -0.1865,  0.0155],\n",
            "        [ 0.0577,  0.0483,  0.0066, -0.1421, -0.0218,  0.0573, -0.0655,  0.0892,\n",
            "         -0.1105,  0.0901],\n",
            "        [-0.0250,  0.1317, -0.1487, -0.2025, -0.2007,  0.1900,  0.1915,  0.1950,\n",
            "          0.1023,  0.0138],\n",
            "        [-0.0253, -0.2263, -0.0107, -0.1052, -0.0309,  0.1138, -0.0093, -0.1307,\n",
            "          0.0476, -0.0651],\n",
            "        [-0.1008, -0.1295, -0.1835,  0.1902,  0.0472, -0.1306,  0.1623,  0.0707,\n",
            "          0.1605,  0.1529]])\n",
            "name='bias', param.data=tensor([ 0.2977,  0.0091, -0.0333, -0.1386,  0.2557,  0.1151, -0.0040,  0.0774,\n",
            "         0.2714,  0.1051])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DDP\n",
        "\n",
        "- Here we use CPU instead of GPU to reduce the system requirement.\n"
      ],
      "metadata": {
        "id": "2McyiArZFVIE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Try 1 - Manually dist the training data.\n",
        "\n",
        "- We expect the trained model weights to be exactly the same as the single CPU scenario."
      ],
      "metadata": {
        "id": "dddZ7RyoRtNG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.distributed as dist\n",
        "import torch.multiprocessing as mp\n",
        "\n",
        "from torch.nn.parallel import DistributedDataParallel as DDP\n",
        "\n",
        "DEVICE = 'cpu'\n",
        "\n",
        "def run_single_process(rank: int, world_size: int):\n",
        "  print(f\"Starting process with {rank=}, {world_size=}\")\n",
        "\n",
        "  # Use the gloo backend for CPU-based distributed processing\n",
        "  dist.init_process_group(backend=\"gloo\", world_size=world_size, rank=rank)\n",
        "\n",
        "  assert rank == dist.get_rank()\n",
        "  assert world_size == dist.get_world_size()\n",
        "  dist.barrier()\n",
        "\n",
        "  split_data_size = 20 // 4\n",
        "\n",
        "  torch.manual_seed(123)\n",
        "\n",
        "  # Create the train set.\n",
        "  if rank == 0:\n",
        "    inputs = torch.randn(20, 10)\n",
        "    inputs_split_list = torch.split(inputs, split_data_size, dim=0)\n",
        "    inputs_split_list = list(inputs_split_list)\n",
        "    assert (20 // split_data_size) == len(inputs_split_list)\n",
        "\n",
        "    targets = torch.randn(20, 10)\n",
        "    targets_split_list = torch.split(targets, split_data_size, dim=0)\n",
        "    targets_split_list = list(targets_split_list)\n",
        "    assert (20 // split_data_size) == len(targets_split_list)\n",
        "  else:\n",
        "    inputs_split_list = None\n",
        "    targets_split_list = None\n",
        "\n",
        "  # Split the train set and send to the distributed workers.\n",
        "  inputs_split = torch.zeros((split_data_size, 10), dtype=torch.float32)\n",
        "  dist.scatter(inputs_split, inputs_split_list, src=0)\n",
        "  inputs_split.to(DEVICE)\n",
        "\n",
        "  targets_split = torch.zeros((split_data_size, 10), dtype=torch.float32)\n",
        "  dist.scatter(targets_split, targets_split_list, src=0)\n",
        "  targets_split.to(DEVICE)\n",
        "\n",
        "  # Init the model\n",
        "  model = torch.nn.Linear(10, 10).to(DEVICE)\n",
        "  ddp_model = DDP(model, device_ids=None)\n",
        "  loss_fn = torch.nn.MSELoss()\n",
        "  optimizer = torch.optim.SGD(ddp_model.parameters(), lr=1)\n",
        "\n",
        "  # forward\n",
        "  optimizer.zero_grad()\n",
        "  outputs = ddp_model(inputs_split)\n",
        "\n",
        "  # Assert the grad is None before backprop\n",
        "  for name, p in model.named_parameters():\n",
        "    assert not p.grad\n",
        "\n",
        "  # backward\n",
        "  loss_fn(outputs, targets_split).backward()\n",
        "\n",
        "  # Assert the grad is not None after backprop\n",
        "  for name, p in model.named_parameters():\n",
        "    if p.requires_grad:\n",
        "      assert p.grad is not None\n",
        "      assert p.shape == p.grad.shape\n",
        "\n",
        "  # check model params\n",
        "  # if rank == 0:\n",
        "  #   print(\"Before backward\")\n",
        "  #   for name, param in ddp_model.named_parameters():\n",
        "  #     if param.requires_grad:\n",
        "  #       print(f\"{name=}, {param.data=}\")\n",
        "\n",
        "  optimizer.step()\n",
        "\n",
        "  # check model params\n",
        "  if rank == 0:\n",
        "    print(\"After backward\")\n",
        "    for name, param in ddp_model.named_parameters():\n",
        "      if param.requires_grad:\n",
        "        print(f\"{name=}, {param.data=}\")\n",
        "\n",
        "  dist.destroy_process_group()\n",
        "\n",
        "os.environ['MASTER_ADDR'] = 'localhost'\n",
        "os.environ['MASTER_PORT'] = '12355' # You can choose a different port if 12355 is in use\n",
        "\n",
        "world_size = 4\n",
        "\n",
        "processes = []\n",
        "for rank in range(world_size):\n",
        "  p = mp.Process(target=run_single_process, args=(rank, world_size))\n",
        "  p.start()\n",
        "  processes.append(p)\n",
        "\n",
        "for p in processes:\n",
        "  p.join()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAPDEnzOJMd5",
        "outputId": "cca4a12a-de1e-401f-ac49-bbcf6d675edc"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting process with rank=0, world_size=4Starting process with rank=1, world_size=4\n",
            "Starting process with rank=2, world_size=4\n",
            "\n",
            "Starting process with rank=3, world_size=4\n",
            "After backward\n",
            "name='module.weight', param.data=tensor([[ 0.0944, -0.1266, -0.1251,  0.1248, -0.0659, -0.0834,  0.1643, -0.1748,\n",
            "          0.1602,  0.2234],\n",
            "        [-0.1549, -0.2573,  0.0233, -0.1648,  0.1694, -0.1869, -0.2008, -0.0400,\n",
            "         -0.0904, -0.2047],\n",
            "        [ 0.1007,  0.1481,  0.0845,  0.1624,  0.0025,  0.2104, -0.2733,  0.2917,\n",
            "          0.1926, -0.1286],\n",
            "        [-0.0789, -0.1440,  0.2480,  0.0249,  0.0506,  0.2015, -0.1588,  0.2132,\n",
            "         -0.2207, -0.1388],\n",
            "        [-0.0530, -0.2940, -0.2188, -0.2619, -0.1186, -0.1148, -0.0541,  0.0963,\n",
            "         -0.0057, -0.1375],\n",
            "        [-0.2125,  0.2258, -0.2172, -0.1571, -0.1958,  0.2219,  0.2494,  0.0186,\n",
            "         -0.1865,  0.0155],\n",
            "        [ 0.0577,  0.0483,  0.0066, -0.1421, -0.0218,  0.0573, -0.0655,  0.0892,\n",
            "         -0.1105,  0.0901],\n",
            "        [-0.0250,  0.1317, -0.1487, -0.2025, -0.2007,  0.1900,  0.1915,  0.1950,\n",
            "          0.1023,  0.0138],\n",
            "        [-0.0253, -0.2263, -0.0107, -0.1052, -0.0309,  0.1138, -0.0093, -0.1307,\n",
            "          0.0476, -0.0651],\n",
            "        [-0.1008, -0.1295, -0.1835,  0.1902,  0.0472, -0.1306,  0.1623,  0.0707,\n",
            "          0.1605,  0.1529]])\n",
            "name='module.bias', param.data=tensor([ 0.2977,  0.0091, -0.0333, -0.1386,  0.2557,  0.1151, -0.0040,  0.0774,\n",
            "         0.2714,  0.1051])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Try 1.a - Manually dist the training data & update the weights\n",
        "\n",
        "- We expect the trained model weights to be exactly the same as the single CPU scenario."
      ],
      "metadata": {
        "id": "f1x238gd67dK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.distributed as dist\n",
        "import torch.multiprocessing as mp\n",
        "\n",
        "from torch.nn.parallel import DistributedDataParallel as DDP\n",
        "\n",
        "DEVICE = 'cpu'\n",
        "\n",
        "def run_single_process(rank: int, world_size: int):\n",
        "  print(f\"Starting process with {rank=}, {world_size=}\")\n",
        "\n",
        "  # Use the gloo backend for CPU-based distributed processing\n",
        "  dist.init_process_group(backend=\"gloo\", world_size=world_size, rank=rank)\n",
        "\n",
        "  assert rank == dist.get_rank()\n",
        "  assert world_size == dist.get_world_size()\n",
        "  dist.barrier()\n",
        "\n",
        "  split_data_size = 20 // 4\n",
        "\n",
        "  torch.manual_seed(123)\n",
        "\n",
        "  # Create the train set.\n",
        "  if rank == 0:\n",
        "    inputs = torch.randn(20, 10)\n",
        "    inputs_split_list = torch.split(inputs, split_data_size, dim=0)\n",
        "    inputs_split_list = list(inputs_split_list)\n",
        "    assert (20 // split_data_size) == len(inputs_split_list)\n",
        "\n",
        "    targets = torch.randn(20, 10)\n",
        "    targets_split_list = torch.split(targets, split_data_size, dim=0)\n",
        "    targets_split_list = list(targets_split_list)\n",
        "    assert (20 // split_data_size) == len(targets_split_list)\n",
        "  else:\n",
        "    inputs_split_list = None\n",
        "    targets_split_list = None\n",
        "\n",
        "  # Split the train set and send to the distributed workers.\n",
        "  inputs_split = torch.zeros((split_data_size, 10), dtype=torch.float32)\n",
        "  dist.scatter(inputs_split, inputs_split_list, src=0)\n",
        "  inputs_split.to(DEVICE)\n",
        "\n",
        "  targets_split = torch.zeros((split_data_size, 10), dtype=torch.float32)\n",
        "  dist.scatter(targets_split, targets_split_list, src=0)\n",
        "  targets_split.to(DEVICE)\n",
        "\n",
        "  # Init the model\n",
        "  model = torch.nn.Linear(10, 10).to(DEVICE)\n",
        "  # The non rank 0 have different weights because they didn't initialize the\n",
        "  # \"inputs\" & \"targets\". So here we sync the rank 0 weights to other ranks.\n",
        "  for name, p in model.named_parameters():\n",
        "    dist.broadcast(p.data, src=0)\n",
        "\n",
        "  loss_fn = torch.nn.MSELoss()\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr=1)\n",
        "\n",
        "  # forward\n",
        "  optimizer.zero_grad()\n",
        "  outputs = model(inputs_split)\n",
        "\n",
        "  # Assert the grad is None before backprop\n",
        "  for name, p in model.named_parameters():\n",
        "    assert not p.grad\n",
        "\n",
        "  # backward\n",
        "  loss_fn(outputs, targets_split).backward()\n",
        "\n",
        "  # Assert the grad is not None after backprop\n",
        "  for name, p in model.named_parameters():\n",
        "    if p.requires_grad:\n",
        "      assert p.grad is not None\n",
        "      assert p.shape == p.grad.shape\n",
        "      assert p.grad.is_contiguous()\n",
        "      # print(f\"{rank=} {p.grad=}\")\n",
        "      # dist.barrier()\n",
        "      dist.broadcast(p.data, src=0)\n",
        "\n",
        "      # RuntimeError: Cannot use ReduceOp.AVG with Gloo\n",
        "      dist.all_reduce(p.grad, dist.ReduceOp.SUM)\n",
        "      p.grad /= 4\n",
        "\n",
        "\n",
        "  # check model params\n",
        "  # if rank == 0:\n",
        "    # print(\"Before backward\")\n",
        "    # for name, param in model.named_parameters():\n",
        "    #   if param.requires_grad:\n",
        "    #     print(f\"{name=}, {param.data=}\")\n",
        "    # dist.barrier()\n",
        "\n",
        "  optimizer.step()\n",
        "\n",
        "  # check model params\n",
        "  if rank == 0:\n",
        "    print(\"After backward\")\n",
        "    for name, param in model.named_parameters():\n",
        "      if param.requires_grad:\n",
        "        print(f\"{name=}, {param.data=}\")\n",
        "\n",
        "  dist.destroy_process_group()\n",
        "\n",
        "os.environ['MASTER_ADDR'] = 'localhost'\n",
        "os.environ['MASTER_PORT'] = '12355' # You can choose a different port if 12355 is in use\n",
        "\n",
        "world_size = 4\n",
        "\n",
        "processes = []\n",
        "for rank in range(world_size):\n",
        "  p = mp.Process(target=run_single_process, args=(rank, world_size))\n",
        "  p.start()\n",
        "  processes.append(p)\n",
        "\n",
        "for p in processes:\n",
        "  p.join()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpgF1Z0u7D1Z",
        "outputId": "495d846d-9f5e-4ee6-b197-fc05e42d7fcc"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting process with rank=0, world_size=4Starting process with rank=1, world_size=4\n",
            "\n",
            "Starting process with rank=2, world_size=4\n",
            "Starting process with rank=3, world_size=4\n",
            "After backward\n",
            "name='weight', param.data=tensor([[ 0.0944, -0.1266, -0.1251,  0.1248, -0.0659, -0.0834,  0.1643, -0.1748,\n",
            "          0.1602,  0.2234],\n",
            "        [-0.1549, -0.2573,  0.0233, -0.1648,  0.1694, -0.1869, -0.2008, -0.0400,\n",
            "         -0.0904, -0.2047],\n",
            "        [ 0.1007,  0.1481,  0.0845,  0.1624,  0.0025,  0.2104, -0.2733,  0.2917,\n",
            "          0.1926, -0.1286],\n",
            "        [-0.0789, -0.1440,  0.2480,  0.0249,  0.0506,  0.2015, -0.1588,  0.2132,\n",
            "         -0.2207, -0.1388],\n",
            "        [-0.0530, -0.2940, -0.2188, -0.2619, -0.1186, -0.1148, -0.0541,  0.0963,\n",
            "         -0.0057, -0.1375],\n",
            "        [-0.2125,  0.2258, -0.2172, -0.1571, -0.1958,  0.2219,  0.2494,  0.0186,\n",
            "         -0.1865,  0.0155],\n",
            "        [ 0.0577,  0.0483,  0.0066, -0.1421, -0.0218,  0.0573, -0.0655,  0.0892,\n",
            "         -0.1105,  0.0901],\n",
            "        [-0.0250,  0.1317, -0.1487, -0.2025, -0.2007,  0.1900,  0.1915,  0.1950,\n",
            "          0.1023,  0.0138],\n",
            "        [-0.0253, -0.2263, -0.0107, -0.1052, -0.0309,  0.1138, -0.0093, -0.1307,\n",
            "          0.0476, -0.0651],\n",
            "        [-0.1008, -0.1295, -0.1835,  0.1902,  0.0472, -0.1306,  0.1623,  0.0707,\n",
            "          0.1605,  0.1529]])\n",
            "name='bias', param.data=tensor([ 0.2977,  0.0091, -0.0333, -0.1386,  0.2557,  0.1151, -0.0040,  0.0774,\n",
            "         0.2714,  0.1051])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Try 2 - use distributed sampler"
      ],
      "metadata": {
        "id": "3awzclzMUJ8N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.distributed as dist\n",
        "import torch.multiprocessing as mp\n",
        "import torchvision"
      ],
      "metadata": {
        "id": "fOEw2jMcFWMI"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 2\n",
        "\n",
        "# This is the global bs. In DPP, it should guarantee the sum of bs on all devices equal to this #.\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "WORLD_SIZE = 4\n",
        "\n",
        "class ToyModel(nn.Module):\n",
        "  def __init__(self):\n",
        "      super(ToyModel, self).__init__()\n",
        "      self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "      self.pool = nn.MaxPool2d(2, 2)\n",
        "      self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "      self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "      self.fc2 = nn.Linear(120, 84)\n",
        "      self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "      x = self.pool(F.relu(self.conv1(x)))\n",
        "      x = self.pool(F.relu(self.conv2(x)))\n",
        "      x = x.view(-1, 16 * 5 * 5)\n",
        "      x = F.relu(self.fc1(x))\n",
        "      x = F.relu(self.fc2(x))\n",
        "      x = self.fc3(x)\n",
        "      return x\n",
        "\n",
        "# from the official doc: https://docs.pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
        "class ToyModel(nn.Module):\n",
        "  def __init__(self):\n",
        "      super().__init__()\n",
        "      self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "      self.pool = nn.MaxPool2d(2, 2)\n",
        "      self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "      self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "      self.fc2 = nn.Linear(120, 84)\n",
        "      self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "      x = self.pool(F.relu(self.conv1(x)))\n",
        "      x = self.pool(F.relu(self.conv2(x)))\n",
        "      x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "      x = F.relu(self.fc1(x))\n",
        "      x = F.relu(self.fc2(x))\n",
        "      x = self.fc3(x)\n",
        "      return x\n",
        "\n",
        "dataset_transform = torchvision.transforms.Compose([\n",
        "      torchvision.transforms.ToTensor(),\n",
        "      torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "  ])"
      ],
      "metadata": {
        "id": "ljM4jc72bxCl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title single CPU version\n",
        "\n",
        "from torch.nn.parallel import DistributedDataParallel as DDP\n",
        "\n",
        "DEVICE = 'cpu'\n",
        "\n",
        "# Init the model\n",
        "model = ToyModel().to(DEVICE)\n",
        "model.train()\n",
        "loss_fn = torch.nn.CrossEntropyLoss().to(DEVICE)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Dataset\n",
        "download_path = \"./data\"\n",
        "my_trainset = torchvision.datasets.CIFAR10(root=download_path, train=True, download=True, transform=dataset_transform)\n",
        "trainloader = torch.utils.data.DataLoader(my_trainset, batch_size=BATCH_SIZE)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  for it, (data, label) in enumerate(trainloader):\n",
        "\n",
        "    # forward\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(data)\n",
        "\n",
        "    # backward\n",
        "    loss = loss_fn(outputs, label)\n",
        "    loss.backward()\n",
        "\n",
        "    if it % 200 == 0:\n",
        "      print(f\"{epoch=}, {it=}, loss={loss.item():.3f}\")\n",
        "\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 773
        },
        "id": "I9X0kAQlbsLS",
        "outputId": "38227978-aba4-416b-9e98-7933144610f6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:03<00:00, 46.9MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch=0, it=0, loss=2.316\n",
            "epoch=0, it=200, loss=2.283\n",
            "epoch=0, it=400, loss=2.300\n",
            "epoch=0, it=600, loss=2.299\n",
            "epoch=0, it=800, loss=2.305\n",
            "epoch=0, it=1000, loss=2.327\n",
            "epoch=0, it=1200, loss=2.172\n",
            "epoch=0, it=1400, loss=2.208\n",
            "epoch=0, it=1600, loss=2.459\n",
            "epoch=0, it=1800, loss=1.976\n",
            "epoch=0, it=2000, loss=2.019\n",
            "epoch=0, it=2200, loss=2.011\n",
            "epoch=0, it=2400, loss=1.939\n",
            "epoch=0, it=2600, loss=1.686\n",
            "epoch=0, it=2800, loss=1.692\n",
            "epoch=0, it=3000, loss=2.043\n",
            "epoch=1, it=0, loss=1.656\n",
            "epoch=1, it=200, loss=2.215\n",
            "epoch=1, it=400, loss=1.709\n",
            "epoch=1, it=600, loss=1.913\n",
            "epoch=1, it=800, loss=1.589\n",
            "epoch=1, it=1000, loss=1.826\n",
            "epoch=1, it=1200, loss=1.525\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1921583010.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \"\"\"\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_float_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title dist version\n",
        "\n",
        "from torch.nn.parallel import DistributedDataParallel as DDP\n",
        "\n",
        "DEVICE = 'cpu'\n",
        "\n",
        "def run_single_process(rank: int, world_size: int):\n",
        "  print(f\"Starting process with {rank=}, {world_size=}\")\n",
        "\n",
        "  # Use the gloo backend for CPU-based distributed processing\n",
        "  dist.init_process_group(backend=\"gloo\", world_size=WORLD_SIZE, rank=rank)\n",
        "\n",
        "  assert rank == dist.get_rank()\n",
        "  assert world_size == dist.get_world_size()\n",
        "  dist.barrier()\n",
        "\n",
        "  torch.manual_seed(123)\n",
        "\n",
        "  # Init the model\n",
        "  # 模型是先注册，再同步的。\n",
        "  # 先定义一个 普通的model(nn.module) 然后再DDP(model)。\n",
        "  # 第二个操作会把master节点(rank 0)的model的parameter和buffer给同步出去。\n",
        "  #\n",
        "  # DDP初始化（也就是model = DDP(model)这一步）\n",
        "  # 1. 把parameter，buffer从master节点传到其他节点，使所有进程上的状态一致。\n",
        "  #   注释：DDP通过这一步保证所有进程的初始状态一致。所以，请确保在这一步之后，你的代码不会再修改模型的任何东西了，包括添加、修改、删除parameter和buffer！\n",
        "  # 2.（可能）如果有每个节点有多卡，则在每张卡上创建模型（类似DP）\n",
        "  # 3. 把parameter进行分组，每一组称为一个bucket。临近的parameter在同一个bucket。\n",
        "  #   注释：这是为了加速，在梯度通讯时，先计算、得到梯度的bucket会马上进行通讯，不必等到所有梯度计算结束才进行通讯。后面会详细介绍。\n",
        "  # 4. 创建管理器reducer，给每个parameter注册梯度平均的hook。\n",
        "  #   注释：这一步的具体实现是在C++代码里面的，即reducer.h文件。\n",
        "  # 5.（可能）为可能的SyncBN层做准备\n",
        "  #\n",
        "  # 在每个step中，DDP模型都会做下面的事情：\n",
        "  # 1. 采样数据，从dataloader得到一个batch的数据，用于当前计算（for data, label in dataloader）。\n",
        "  #   注释：因为我们的dataloader使用了DistributedSampler，所以各个进程之间的数据是不会重复的。如果要确保DDP性能和单卡性能一致，这边需要保证在数据上，DDP模式下的一个epoch和单卡下的一个epoch是等效的。\n",
        "  # 2. 进行网络的前向计算（prediction = model(data)）\n",
        "  #   2.1 同步各进程状态\n",
        "  #     2.1.1（可能）对单进程多卡复制模式，要在进程内同步多卡之间的parameter和buffer\n",
        "  #     2.1.2 同步各进程之间的buffer。\n",
        "  #   2.2 接下来才是进行真正的前向计算\n",
        "  #   2.3（可能）当DDP参数find_unused_parameter为true时，其会在forward结束时，启动一个回溯，标记出所有没被用到的parameter，提前把这些设定为ready。\n",
        "  #     注释：find_unused_parameter的默认值是false，因为其会拖慢速度。\n",
        "  # 3. 计算梯度（loss.backward()）\n",
        "  #   3.1 reducer外面：各个进程各自开始反向地计算梯度。\n",
        "  #     3.1.1 注释：梯度是反向计算的，所以最后面的参数反而是最先得到梯度的。\n",
        "  #   3.2 reducer外面：当某个parameter的梯度计算好了的时候，其之前注册的grad hook就会被触发，在reducer里把这个parameter的状态标记为ready。\n",
        "  #   3.3 reducer里面：当某个bucket的所有parameter都是ready状态时，reducer会开始对这个bucket的所有parameter都开始一个异步的all-reduce梯度平均操作。\n",
        "  #     注释：\n",
        "  #       3.3.1 bucket的执行过程也是有顺序的，其顺序与parameter是相反的，即最先注册的parameter的bucket在最后面。\n",
        "  #       3.3.2 所以，我们在创建module的时候，请务必把先进行计算的parameter注册在前面，后计算的在后面。不然，reducer会卡在某一个bucket等待，使训练时间延长！\n",
        "  #         3.3.2.1 所谓的参数注册，其实就是创建网络层。也就是要求按照网络计算顺序，依次创建网络层。\n",
        "  #   3.4 reducer里面：当所有bucket的梯度平均都结束后，reducer才会把得到的平均grad结果正式写入到parameter.grad里面。\n",
        "  #   注释：这一步，感觉没有必要等全部结束之后才进行。可能得对照一下源码。\n",
        "  # 4. 优化器optimizer应用gradient，更新参数（optimizer.step()）。\n",
        "  #   注释：这一步，是和DDP没关系的。\n",
        "  model = ToyModel().to(DEVICE)\n",
        "  ddp_model = DDP(model, device_ids=None)\n",
        "  ddp_model.train()\n",
        "  loss_fn = torch.nn.CrossEntropyLoss().to(DEVICE)\n",
        "\n",
        "  # Init the optimizer.\n",
        "  #\n",
        "  # 我们可以看到，因为optimizer和DDP是没有关系的，所以optimizer初始状态的同一性是不被DDP保证的！\n",
        "  # 大多数官方optimizer，其实现能保证从同样状态的model初始化时，其初始状态是相同的。\n",
        "  # 所以这边我们只要保证在DDP模型创建后才初始化optimizer，就不用做额外的操作。\n",
        "  # 但是，如果自定义optimizer，则需要你自己来保证其统一性！\n",
        "  # 回顾一下文章最开始的代码，你会发现，optimizer确实是在DDP之后定义的。这个时候的模式已经是被初始化为相同的参数，所以能够保证优化器的初始状态是相同的。\n",
        "  optimizer = torch.optim.SGD(ddp_model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "  # Dataset\n",
        "  download_path = f\"./data_{rank}\"\n",
        "  my_trainset = torchvision.datasets.CIFAR10(root=download_path, train=True, download=True, transform=dataset_transform)\n",
        "  # DDP：使用DistributedSampler，DDP帮我们把细节都封装起来了。\n",
        "  #      用，就完事儿！\n",
        "  train_sampler = torch.utils.data.distributed.DistributedSampler(my_trainset)\n",
        "  # DDP：需要注意的是，这里的batch_size指的是每个进程下的batch_size。\n",
        "  #      也就是说，总batch_size是这里的batch_size再乘以并行数(world_size)。\n",
        "  assert BATCH_SIZE % WORLD_SIZE == 0\n",
        "  trainloader = torch.utils.data.DataLoader(my_trainset, batch_size=BATCH_SIZE//WORLD_SIZE, sampler=train_sampler)\n",
        "\n",
        "  for epoch in range(EPOCHS):\n",
        "    # The distributed training loss is not going to be the same as the single device training.\n",
        "    # The reason is that the distributed sampler uses \"epoch\" as the sampling seed in each host.\n",
        "    #\n",
        "    # 不知道你有没有好奇，为什么给dataloader加一个DistributedSampler，就可以无缝对接DDP模式呢？\n",
        "    # 其实原理很简单，就是给不同进程分配数据集的不重叠、不交叉部分。\n",
        "    # 那么问题来了，每次epoch我们都会随机shuffle数据集，那么，不同进程之间要怎么保持shuffle后数据集的一致性呢？\n",
        "    # DistributedSampler的实现方式是，不同进程会使用一个相同的随机数种子，这样shuffle出来的东西就能确保一致。\n",
        "    #\n",
        "    # 具体实现上，DistributedSampler使用当前epoch作为随机数种子，从而使得不同epoch下有不同的shuffle结果。\n",
        "    # 所以，记得每次epoch开始前都要调用一下sampler的set_epoch方法，这样才能让数据集随机shuffle起来。\n",
        "    trainloader.sampler.set_epoch(epoch)\n",
        "\n",
        "    for it, (data, label) in enumerate(trainloader):\n",
        "\n",
        "      # forward\n",
        "      optimizer.zero_grad()\n",
        "      outputs = ddp_model(data)\n",
        "\n",
        "      # backward\n",
        "      loss = loss_fn(outputs, label)\n",
        "      # The updated gradients are communicated to all workers during backward()\n",
        "      # It divides the models and params to buckets, and eagerly to communicate\n",
        "      # the buckets whose gradient calculation are finished, to reduce latency.\n",
        "      #\n",
        "      # see more in https://zhuanlan.zhihu.com/p/485208899\n",
        "      loss.backward()\n",
        "\n",
        "      if rank == 0 and it % 200 == 0:\n",
        "        print(f\"{epoch=}, {it=}, loss={loss.item():.3f}\")\n",
        "\n",
        "      optimizer.step()\n",
        "\n",
        "  dist.destroy_process_group()\n",
        "\n",
        "\n",
        "\n",
        "os.environ['MASTER_ADDR'] = 'localhost'\n",
        "os.environ['MASTER_PORT'] = '12355' # You can choose a different port if 12355 is in use\n",
        "\n",
        "processes = []\n",
        "for rank in range(WORLD_SIZE):\n",
        "  p = mp.Process(target=run_single_process, args=(rank, WORLD_SIZE))\n",
        "  p.start()\n",
        "  processes.append(p)\n",
        "\n",
        "for p in processes:\n",
        "  p.join()"
      ],
      "metadata": {
        "id": "ez5NWWEDUQLj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Speed up the Batch Inference\n",
        "\n",
        "- Idea is to distribute the data in the batch inference to different GPUs\n",
        "- No need to use the **DDP** wrapper, because it helps only the back-prop\n",
        "\n",
        "解决问题的思路很简单，就是各个进程中各自进行单卡的inference，然后把结果收集到一起。单卡inference很简单，我们甚至可以直接用DDP包装前的模型。问题其实只有两个：\n",
        "- 我们要如何把数据split到各个进程中\n",
        "- 我们要如何把结果合并到一起\n",
        "\n",
        "如何把数据split到各个进程中：新的data sampler\n",
        "大家肯定还记得，在训练的时候，我们用的 torch.utils.data.distributed.DistributedSampler帮助我们把数据不重复地分到各个进程上去。但是，其分的方法是：每段连续的N个数据，拆成一个一个，分给N个进程，所以每个进程拿到的数据不是连续的。这样，*不利于我们在inference结束的时候将结果合并到一起*。\n",
        "\n",
        "所以，这里我们需要实现一个新的data sampler。它的功能，是能够连续地划分数据块，不重复地分到各个进程上去。"
      ],
      "metadata": {
        "id": "yISx9wUdEEsd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title The sampler that shard the data sequentially\n",
        "\n",
        "# This makes it easier to gather & combine the results.\n",
        "\n",
        "import math\n",
        "\n",
        "class SequentialDistributionSampler(torch.utils.data.sampler.Sampler):\n",
        "  pass\n",
        "\n",
        "  def __init__(self, dataset, batch_size, rank: int, num_replicas: int):\n",
        "    self.dataset = dataset\n",
        "    self.batch_size = batch_size\n",
        "    self.rank = rank\n",
        "    self.num_replicas = num_replicas\n",
        "    # The # of samples in a single node.\n",
        "    self.num_samples = math.ceil(len(self.dataset) / num_replicas)\n",
        "    self.total_size = self.num_samples * num_replicas\n",
        "\n",
        "  def __iter__(self):\n",
        "    indices = list(range(len(self.dataset)))\n",
        "    indices += [-1] * (self.total_size - len(indices))\n",
        "    indices = indices[rank * self.num_samples : (rank + 1) * self.num_samples]\n",
        "    return iter(indices)\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.num_samples"
      ],
      "metadata": {
        "id": "yVV-DHKOE7bX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = 'cpu'\n",
        "\n",
        "def eval_single_process(rank: int, world_size: int):\n",
        "  print(f\"Starting process with {rank=}, {world_size=}\")\n",
        "\n",
        "  # Use the gloo backend for CPU-based distributed processing\n",
        "  dist.init_process_group(backend=\"gloo\", world_size=WORLD_SIZE, rank=rank)\n",
        "\n",
        "  assert rank == dist.get_rank()\n",
        "  assert world_size == dist.get_world_size()\n",
        "  dist.barrier()\n",
        "\n",
        "  download_path = f\"./data_{rank}\"\n",
        "  my_trainset = torchvision.datasets.CIFAR10(root=download_path, train=True, download=True, transform=dataset_transform)\n",
        "\n",
        "  sampler = SequentialDistributionSampler(dataset=my_trainset, batch_size=BATCH_SIZE, rank=rank, num_replicas=world_size)\n",
        "  evalloader = torch.utils.data.DataLoader(my_trainset, batch_size=BATCH_SIZE//WORLD_SIZE, sampler=sampler)\n",
        "\n",
        "  model = ToyModel().to(DEVICE)\n",
        "\n",
        "  results = None\n",
        "  for it, (data, label) in enumerate(evalloader):\n",
        "      # forward\n",
        "      optimizer.zero_grad()\n",
        "      outputs = model(data)\n",
        "\n",
        "      if results is not None:\n",
        "        results = torch.cat((results, outputs), dim = 0)\n",
        "      else:\n",
        "        results = outputs\n",
        "\n",
        "      if rank == 0 and it % 200 == 0:\n",
        "        print(f\"{it=}, num of results = {len(results) if results is not None else 0}\")\n",
        "\n",
        "      # break\n",
        "\n",
        "  if rank == 0:\n",
        "    gathered = [torch.zeros(results.shape, dtype=torch.float32) for _ in range(world_size)]\n",
        "  else:\n",
        "    gathered = None\n",
        "  dist.gather(results, gather_list=gathered, dst=0)\n",
        "\n",
        "  if rank == 0:\n",
        "    gathered_t = torch.cat(gathered, axis=0)\n",
        "    valid_gathered_t = gathered_t[:len(my_trainset)]\n",
        "    print(f\"Gathered eval results size = {gathered_t.shape}, valid results size = {valid_gathered_t.shape}\")\n",
        "\n",
        "\n",
        "os.environ['MASTER_ADDR'] = 'localhost'\n",
        "os.environ['MASTER_PORT'] = '12355' # You can choose a different port if 12355 is in use\n",
        "\n",
        "processes = []\n",
        "for rank in range(WORLD_SIZE):\n",
        "  p = mp.Process(target=eval_single_process, args=(rank, WORLD_SIZE))\n",
        "  p.start()\n",
        "  processes.append(p)\n",
        "\n",
        "for p in processes:\n",
        "  p.join()"
      ],
      "metadata": {
        "id": "DmSD1N5fKsfn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}