{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNNtbYwDWIckMfblPYigAPv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lizhieffe/llm_knowledge/blob/main/PyTorch_DDP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Reference: https://zhuanlan.zhihu.com/p/178402798"
      ],
      "metadata": {
        "id": "1uxUUCXZ9_T3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Single GPU"
      ],
      "metadata": {
        "id": "U6XXpSa1FRZZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "DEVICE = 'cpu'\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "# Init\n",
        "input = torch.randn(20, 10).to(DEVICE) # (20, 10)\n",
        "labels = torch.randn(20, 10).to(DEVICE)\n",
        "\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "\n",
        "model = torch.nn.Linear(10, 10).to(DEVICE)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1)\n",
        "\n",
        "for it in range(1):\n",
        "  # forward\n",
        "  optimizer.zero_grad()\n",
        "  outputs = model(input)\n",
        "\n",
        "  # backward\n",
        "  loss_fn(outputs, labels).backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  # check model params\n",
        "  print(f\"In epoch {it}\")\n",
        "  for name, param in model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "      print(f\"{name=}, {param.data=}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g90S9hU6BQ2D",
        "outputId": "d96f895c-7836-4568-f069-d732feb19c31"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In epoch 0\n",
            "name='weight', param.data=tensor([[ 0.0944, -0.1266, -0.1251,  0.1248, -0.0659, -0.0834,  0.1643, -0.1748,\n",
            "          0.1602,  0.2234],\n",
            "        [-0.1549, -0.2573,  0.0233, -0.1648,  0.1694, -0.1869, -0.2008, -0.0400,\n",
            "         -0.0904, -0.2047],\n",
            "        [ 0.1007,  0.1481,  0.0845,  0.1624,  0.0025,  0.2104, -0.2733,  0.2917,\n",
            "          0.1926, -0.1286],\n",
            "        [-0.0789, -0.1440,  0.2480,  0.0249,  0.0506,  0.2015, -0.1588,  0.2132,\n",
            "         -0.2207, -0.1388],\n",
            "        [-0.0530, -0.2940, -0.2188, -0.2619, -0.1186, -0.1148, -0.0541,  0.0963,\n",
            "         -0.0057, -0.1375],\n",
            "        [-0.2125,  0.2258, -0.2172, -0.1571, -0.1958,  0.2219,  0.2494,  0.0186,\n",
            "         -0.1865,  0.0155],\n",
            "        [ 0.0577,  0.0483,  0.0066, -0.1421, -0.0218,  0.0573, -0.0655,  0.0892,\n",
            "         -0.1105,  0.0901],\n",
            "        [-0.0250,  0.1317, -0.1487, -0.2025, -0.2007,  0.1900,  0.1915,  0.1950,\n",
            "          0.1023,  0.0138],\n",
            "        [-0.0253, -0.2263, -0.0107, -0.1052, -0.0309,  0.1138, -0.0093, -0.1307,\n",
            "          0.0476, -0.0651],\n",
            "        [-0.1008, -0.1295, -0.1835,  0.1902,  0.0472, -0.1306,  0.1623,  0.0707,\n",
            "          0.1605,  0.1529]])\n",
            "name='bias', param.data=tensor([ 0.2977,  0.0091, -0.0333, -0.1386,  0.2557,  0.1151, -0.0040,  0.0774,\n",
            "         0.2714,  0.1051])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DDP\n",
        "\n",
        "- Here we use CPU instead of GPU to reduce the system requirement.\n"
      ],
      "metadata": {
        "id": "2McyiArZFVIE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Try 1 - Manually dist the training data.\n",
        "\n",
        "- We expect the trained model weights to be exactly the same as the single CPU scenario."
      ],
      "metadata": {
        "id": "dddZ7RyoRtNG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.distributed as dist\n",
        "import torch.multiprocessing as mp\n",
        "\n",
        "from torch.nn.parallel import DistributedDataParallel as DDP\n",
        "\n",
        "DEVICE = 'cpu'\n",
        "\n",
        "def run_single_process(rank: int, world_size: int):\n",
        "  print(f\"Starting process with {rank=}, {world_size=}\")\n",
        "\n",
        "  # Use the gloo backend for CPU-based distributed processing\n",
        "  dist.init_process_group(backend=\"gloo\", world_size=world_size, rank=rank)\n",
        "\n",
        "  assert rank == dist.get_rank()\n",
        "  assert world_size == dist.get_world_size()\n",
        "  dist.barrier()\n",
        "\n",
        "  split_data_size = 20 // 4\n",
        "\n",
        "  torch.manual_seed(123)\n",
        "\n",
        "  # Create the train set.\n",
        "  if rank == 0:\n",
        "    inputs = torch.randn(20, 10)\n",
        "    inputs_split_list = torch.split(inputs, split_data_size, dim=0)\n",
        "    inputs_split_list = list(inputs_split_list)\n",
        "    assert (20 // split_data_size) == len(inputs_split_list)\n",
        "\n",
        "    targets = torch.randn(20, 10)\n",
        "    targets_split_list = torch.split(targets, split_data_size, dim=0)\n",
        "    targets_split_list = list(targets_split_list)\n",
        "    assert (20 // split_data_size) == len(targets_split_list)\n",
        "  else:\n",
        "    inputs_split_list = None\n",
        "    targets_split_list = None\n",
        "\n",
        "  # Split the train set and send to the distributed workers.\n",
        "  inputs_split = torch.zeros((split_data_size, 10), dtype=torch.float32)\n",
        "  dist.scatter(inputs_split, inputs_split_list, src=0)\n",
        "  inputs_split.to(DEVICE)\n",
        "\n",
        "  targets_split = torch.zeros((split_data_size, 10), dtype=torch.float32)\n",
        "  dist.scatter(targets_split, targets_split_list, src=0)\n",
        "  targets_split.to(DEVICE)\n",
        "\n",
        "  # Init the model\n",
        "  model = torch.nn.Linear(10, 10).to(DEVICE)\n",
        "  ddp_model = DDP(model, device_ids=None)\n",
        "  loss_fn = torch.nn.MSELoss()\n",
        "  optimizer = torch.optim.SGD(ddp_model.parameters(), lr=1)\n",
        "\n",
        "  # forward\n",
        "  optimizer.zero_grad()\n",
        "  outputs = ddp_model(inputs_split)\n",
        "\n",
        "  # backward\n",
        "  loss_fn(outputs, targets_split).backward()\n",
        "\n",
        "  # check model params\n",
        "  # if rank == 0:\n",
        "  #   print(\"Before backward\")\n",
        "  #   for name, param in ddp_model.named_parameters():\n",
        "  #     if param.requires_grad:\n",
        "  #       print(f\"{name=}, {param.data=}\")\n",
        "\n",
        "  optimizer.step()\n",
        "\n",
        "  # check model params\n",
        "  if rank == 0:\n",
        "    print(\"After backward\")\n",
        "    for name, param in ddp_model.named_parameters():\n",
        "      if param.requires_grad:\n",
        "        print(f\"{name=}, {param.data=}\")\n",
        "\n",
        "  dist.destroy_process_group()\n",
        "\n",
        "os.environ['MASTER_ADDR'] = 'localhost'\n",
        "os.environ['MASTER_PORT'] = '12355' # You can choose a different port if 12355 is in use\n",
        "\n",
        "world_size = 4\n",
        "\n",
        "processes = []\n",
        "for rank in range(world_size):\n",
        "  p = mp.Process(target=run_single_process, args=(rank, world_size))\n",
        "  p.start()\n",
        "  processes.append(p)\n",
        "\n",
        "for p in processes:\n",
        "  p.join()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAPDEnzOJMd5",
        "outputId": "00feb22f-eb4b-46ed-aa03-5067b1d6bb39"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting process with rank=0, world_size=4\n",
            "Starting process with rank=1, world_size=4\n",
            "Starting process with rank=2, world_size=4\n",
            "Starting process with rank=3, world_size=4\n",
            "After backward\n",
            "name='module.weight', param.data=tensor([[ 0.0944, -0.1266, -0.1251,  0.1248, -0.0659, -0.0834,  0.1643, -0.1748,\n",
            "          0.1602,  0.2234],\n",
            "        [-0.1549, -0.2573,  0.0233, -0.1648,  0.1694, -0.1869, -0.2008, -0.0400,\n",
            "         -0.0904, -0.2047],\n",
            "        [ 0.1007,  0.1481,  0.0845,  0.1624,  0.0025,  0.2104, -0.2733,  0.2917,\n",
            "          0.1926, -0.1286],\n",
            "        [-0.0789, -0.1440,  0.2480,  0.0249,  0.0506,  0.2015, -0.1588,  0.2132,\n",
            "         -0.2207, -0.1388],\n",
            "        [-0.0530, -0.2940, -0.2188, -0.2619, -0.1186, -0.1148, -0.0541,  0.0963,\n",
            "         -0.0057, -0.1375],\n",
            "        [-0.2125,  0.2258, -0.2172, -0.1571, -0.1958,  0.2219,  0.2494,  0.0186,\n",
            "         -0.1865,  0.0155],\n",
            "        [ 0.0577,  0.0483,  0.0066, -0.1421, -0.0218,  0.0573, -0.0655,  0.0892,\n",
            "         -0.1105,  0.0901],\n",
            "        [-0.0250,  0.1317, -0.1487, -0.2025, -0.2007,  0.1900,  0.1915,  0.1950,\n",
            "          0.1023,  0.0138],\n",
            "        [-0.0253, -0.2263, -0.0107, -0.1052, -0.0309,  0.1138, -0.0093, -0.1307,\n",
            "          0.0476, -0.0651],\n",
            "        [-0.1008, -0.1295, -0.1835,  0.1902,  0.0472, -0.1306,  0.1623,  0.0707,\n",
            "          0.1605,  0.1529]])\n",
            "name='module.bias', param.data=tensor([ 0.2977,  0.0091, -0.0333, -0.1386,  0.2557,  0.1151, -0.0040,  0.0774,\n",
            "         0.2714,  0.1051])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Try 2 - use distributed sampler"
      ],
      "metadata": {
        "id": "3awzclzMUJ8N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ToyModel(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "      super(ToyModel, self).__init__()\n",
        "      self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "      self.pool = nn.MaxPool2d(2, 2)\n",
        "      self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "      self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "      self.fc2 = nn.Linear(120, 84)\n",
        "      self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "      x = self.pool(F.relu(self.conv1(x)))\n",
        "      x = self.pool(F.relu(self.conv2(x)))\n",
        "      x = x.view(-1, 16 * 5 * 5)\n",
        "      x = F.relu(self.fc1(x))\n",
        "      x = F.relu(self.fc2(x))\n",
        "      x = self.fc3(x)\n",
        "      return x\n",
        "\n",
        "# from the official doc: https://docs.pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
        "class ToyModel(nn.Module):\n",
        "  def __init__(self):\n",
        "      super().__init__()\n",
        "      self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "      self.pool = nn.MaxPool2d(2, 2)\n",
        "      self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "      self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "      self.fc2 = nn.Linear(120, 84)\n",
        "      self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "      x = self.pool(F.relu(self.conv1(x)))\n",
        "      x = self.pool(F.relu(self.conv2(x)))\n",
        "      x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "      x = F.relu(self.fc1(x))\n",
        "      x = F.relu(self.fc2(x))\n",
        "      x = self.fc3(x)\n",
        "      return x"
      ],
      "metadata": {
        "id": "ljM4jc72bxCl"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title single CPU version\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.distributed as dist\n",
        "import torch.multiprocessing as mp\n",
        "import torchvision\n",
        "\n",
        "from torch.nn.parallel import DistributedDataParallel as DDP\n",
        "\n",
        "DEVICE = 'cpu'\n",
        "\n",
        "# Init the model\n",
        "model = ToyModel().to(DEVICE)\n",
        "model.train()\n",
        "loss_fn = torch.nn.CrossEntropyLoss().to(DEVICE)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Dataset\n",
        "transform = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "download_path = \"./data\"\n",
        "my_trainset = torchvision.datasets.CIFAR10(root=download_path, train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(my_trainset, batch_size=16)\n",
        "\n",
        "for epoch in range(1):\n",
        "  for it, (data, label) in enumerate(trainloader):\n",
        "\n",
        "    # forward\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(data)\n",
        "\n",
        "    # backward\n",
        "    loss = loss_fn(outputs, label)\n",
        "    loss.backward()\n",
        "\n",
        "    if it % 200 == 0:\n",
        "      print(f\"{epoch=}, {it=}, loss={loss.item():.3f}\")\n",
        "\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9X0kAQlbsLS",
        "outputId": "01534beb-3491-4c2b-82ed-78ea63812027"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch=0, it=0, loss=2.311\n",
            "epoch=0, it=200, loss=2.296\n",
            "epoch=0, it=400, loss=2.280\n",
            "epoch=0, it=600, loss=2.284\n",
            "epoch=0, it=800, loss=2.257\n",
            "epoch=0, it=1000, loss=2.307\n",
            "epoch=0, it=1200, loss=2.150\n",
            "epoch=0, it=1400, loss=2.144\n",
            "epoch=0, it=1600, loss=2.273\n",
            "epoch=0, it=1800, loss=1.866\n",
            "epoch=0, it=2000, loss=1.904\n",
            "epoch=0, it=2200, loss=1.905\n",
            "epoch=0, it=2400, loss=1.841\n",
            "epoch=0, it=2600, loss=1.785\n",
            "epoch=0, it=2800, loss=1.831\n",
            "epoch=0, it=3000, loss=2.042\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title dist version\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.distributed as dist\n",
        "import torch.multiprocessing as mp\n",
        "import torchvision\n",
        "\n",
        "from torch.nn.parallel import DistributedDataParallel as DDP\n",
        "\n",
        "DEVICE = 'cpu'\n",
        "\n",
        "class ToyModel(nn.Module):\n",
        "  def __init__(self):\n",
        "      super(ToyModel, self).__init__()\n",
        "      self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "      self.pool = nn.MaxPool2d(2, 2)\n",
        "      self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "      self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "      self.fc2 = nn.Linear(120, 84)\n",
        "      self.fc3 = nn.Linear(84, 10)\n",
        "  def forward(self, x):\n",
        "      x = self.pool(F.relu(self.conv1(x)))\n",
        "      x = self.pool(F.relu(self.conv2(x)))\n",
        "      x = x.view(-1, 16 * 5 * 5)\n",
        "      x = F.relu(self.fc1(x))\n",
        "      x = F.relu(self.fc2(x))\n",
        "      x = self.fc3(x)\n",
        "      return x\n",
        "\n",
        "def run_single_process(rank: int, world_size: int):\n",
        "  print(f\"Starting process with {rank=}, {world_size=}\")\n",
        "\n",
        "  # Use the gloo backend for CPU-based distributed processing\n",
        "  dist.init_process_group(backend=\"gloo\", world_size=world_size, rank=rank)\n",
        "\n",
        "  assert rank == dist.get_rank()\n",
        "  assert world_size == dist.get_world_size()\n",
        "  dist.barrier()\n",
        "\n",
        "  torch.manual_seed(123)\n",
        "\n",
        "  # Init the model\n",
        "  model = ToyModel().to(DEVICE)\n",
        "  ddp_model = DDP(model, device_ids=None)\n",
        "  ddp_model.train()\n",
        "  loss_fn = torch.nn.CrossEntropyLoss().to(DEVICE)\n",
        "  optimizer = torch.optim.SGD(ddp_model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "  # Dataset\n",
        "  transform = torchvision.transforms.Compose([\n",
        "      torchvision.transforms.ToTensor(),\n",
        "      torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "  ])\n",
        "  download_path = f\"./data_{rank}\"\n",
        "  my_trainset = torchvision.datasets.CIFAR10(root=download_path, train=True, download=True, transform=transform)\n",
        "  train_sampler = torch.utils.data.distributed.DistributedSampler(my_trainset)\n",
        "  trainloader = torch.utils.data.DataLoader(my_trainset, batch_size=16, sampler=train_sampler)\n",
        "\n",
        "  for epoch in range(10):\n",
        "    trainloader.sampler.set_epoch(epoch)\n",
        "\n",
        "    for it, (data, label) in enumerate(trainloader):\n",
        "\n",
        "      # forward\n",
        "      optimizer.zero_grad()\n",
        "      outputs = ddp_model(data)\n",
        "\n",
        "      # backward\n",
        "      loss = loss_fn(outputs, label)\n",
        "      loss.backward()\n",
        "\n",
        "      if rank == 0 and it % 200 == 0:\n",
        "        print(f\"{epoch=}, {it=}, loss={loss.item():.3f}\")\n",
        "\n",
        "      optimizer.step()\n",
        "\n",
        "  dist.destroy_process_group()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "os.environ['MASTER_ADDR'] = 'localhost'\n",
        "os.environ['MASTER_PORT'] = '12355' # You can choose a different port if 12355 is in use\n",
        "\n",
        "world_size = 4\n",
        "\n",
        "processes = []\n",
        "for rank in range(world_size):\n",
        "  p = mp.Process(target=run_single_process, args=(rank, world_size))\n",
        "  p.start()\n",
        "  processes.append(p)\n",
        "\n",
        "for p in processes:\n",
        "  p.join()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ez5NWWEDUQLj",
        "outputId": "238dfa0d-c874-4427-ca34-c5419efa9501"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting process with rank=0, world_size=4Starting process with rank=1, world_size=4\n",
            "\n",
            "Starting process with rank=2, world_size=4\n",
            "Starting process with rank=3, world_size=4\n",
            "epoch=0, it=0, loss=2.279\n",
            "epoch=0, it=200, loss=2.307\n",
            "epoch=0, it=400, loss=2.318\n",
            "epoch=0, it=600, loss=2.288\n",
            "epoch=1, it=0, loss=2.294\n",
            "epoch=1, it=200, loss=2.279\n",
            "epoch=1, it=400, loss=2.239\n",
            "epoch=1, it=600, loss=2.097\n",
            "epoch=2, it=0, loss=2.203\n",
            "epoch=2, it=200, loss=2.002\n",
            "epoch=2, it=400, loss=1.780\n",
            "epoch=2, it=600, loss=1.853\n",
            "epoch=3, it=0, loss=2.172\n",
            "epoch=3, it=200, loss=1.627\n",
            "epoch=3, it=400, loss=1.575\n",
            "epoch=3, it=600, loss=1.668\n",
            "epoch=4, it=0, loss=1.775\n",
            "epoch=4, it=200, loss=1.398\n",
            "epoch=4, it=400, loss=1.625\n",
            "epoch=4, it=600, loss=1.846\n",
            "epoch=5, it=0, loss=1.719\n",
            "epoch=5, it=200, loss=1.477\n",
            "epoch=5, it=400, loss=2.220\n",
            "epoch=5, it=600, loss=1.522\n",
            "epoch=6, it=0, loss=1.281\n",
            "epoch=6, it=200, loss=1.594\n",
            "epoch=6, it=400, loss=1.658\n",
            "epoch=6, it=600, loss=1.494\n",
            "epoch=7, it=0, loss=1.261\n",
            "epoch=7, it=200, loss=1.528\n",
            "epoch=7, it=400, loss=0.907\n",
            "epoch=7, it=600, loss=1.332\n",
            "epoch=8, it=0, loss=1.525\n",
            "epoch=8, it=200, loss=1.803\n",
            "epoch=8, it=400, loss=1.120\n",
            "epoch=8, it=600, loss=0.952\n",
            "epoch=9, it=0, loss=1.168\n",
            "epoch=9, it=200, loss=1.186\n",
            "epoch=9, it=400, loss=1.672\n",
            "epoch=9, it=600, loss=1.382\n"
          ]
        }
      ]
    }
  ]
}